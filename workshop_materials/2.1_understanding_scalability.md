# 2.1 Understanding Scalability
**Duration: 30 minutes**

---

## ğŸ¯ Learning Objectives

By the end of this module, students will:
- Understand the fundamental difference between scalability and performance
- Recognize the relationship between latency and throughput
- Analyze real-world system failures through the lens of scalability
- Identify when to apply vertical vs horizontal scaling strategies

---

## ğŸ“‹ Module Outline

| Section | Time | Type |
|---------|------|------|
| 2.1.1 Case Study - 2 | 5 min | Discussion |
| 2.1.2 What is Scalability? | 7 min | Lecture |
| 2.1.3 Performance | 5 min | Lecture |
| 2.1.4 Scalability vs Performance | 8 min | Lecture + Demo |
| 2.1.5 Latency vs Throughput | 5 min | Lecture |

---

## 2.1.1 Case Study - 2: AWS October 2025 Outage

### ğŸ—£ï¸ Opening Hook (2 min)

> "On October 20, 2025, a single deleted DNS record brought down some of the biggest services on the internetâ€”Snapchat, Fortnite, and thousands of AWS-dependent applicationsâ€”for over **15 hours**. But here's the twist: the DNS record was fixed within minutes. So why did it take 15 hours to recover?"

### The Incident

**Duration:** 15+ hours  
**Affected Region:** AWS US-East-1  
**Root Cause:** A race condition in DynamoDB's automated DNS management deleted the main DNS record for the entire region.

### What Actually Happened

```
Timeline of the Cascade:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  DNS Record   â†’   SDKs Start  â†’  EC2 Control  â†’  Network    â†’  NLB Health
  Deleted          Retrying        Overloaded      Saturated     Checks Fail
     |                |               |               |              |
  2:00 AM         2:05 AM        2:30 AM         5:00 AM        5:30 AM
                                                                     â†“
                                                              Recovery begins
                                                                 2:09 PM
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### The Scalability Lesson

The **initial failure** (DNS deletion) was fixed quickly. But the **recovery created a bigger problem**:

1. **Millions of SDKs** were waiting with exponential backoff
2. When DNS came back, they **all retried at once**
3. The **control plane couldn't scale** to handle the surge
4. **Health checks** (meant to detect problems) became **part of the problem**

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     THE THUNDERING HERD PATTERN    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              
   Normal Traffic        DNS Fails           DNS Fixed
        â”‚                    â”‚                   â”‚
        â–¼                    â–¼                   â–¼
   â•â•â•â•â•â•â•â•â•â•          â•â•â•â•â•â•â•â•â•â•          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
   â•â•â•â•â•â•â•â•â•â•   â†’      â•â•â•waitingâ•â•â•  â†’    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â† SURGE!
   â•â•â•â•â•â•â•â•â•â•          â•â•â•â•â•â•â•â•â•â•          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
        â”‚                    â”‚                   â”‚
   100 req/s             0 req/s           50,000 req/s
                                                 â”‚
                                                 â–¼
                                         SYSTEM COLLAPSE
```

### ğŸ“ Key Insight

> "The system was designed for **steady-state load**, not **recovery surge**. Scalability isn't just about handling growthâ€”it's about handling **change**."

### Discussion Questions (2 min)

1. Why didn't exponential backoff prevent the thundering herd?
2. What would you add to prevent synchronized retries?

**Answer:** Jitter (randomness). Without it, exponential backoff just changes the timing of the waves.

---

## 2.1.2 What is Scalability?

### Definition

> **Scalability** is the capability of a system to handle a growing amount of work by adding resources.

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         SCALABILITY TYPES          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   VERTICAL SCALING   â”‚     â”‚   HORIZONTAL SCALING     â”‚
   â”‚   (Scale UP)         â”‚     â”‚   (Scale OUT)            â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚                      â”‚     â”‚                          â”‚
   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚     â”‚  â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”      â”‚
   â”‚   â”‚            â”‚     â”‚     â”‚  â”‚ S â”‚ â”‚ S â”‚ â”‚ S â”‚      â”‚
   â”‚   â”‚   BIGGER   â”‚     â”‚     â”‚  â”‚ 1 â”‚ â”‚ 2 â”‚ â”‚ 3 â”‚      â”‚
   â”‚   â”‚   SERVER   â”‚     â”‚     â”‚  â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜      â”‚
   â”‚   â”‚            â”‚     â”‚     â”‚         +                â”‚
   â”‚   â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚     â”‚     â”‚  â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”      â”‚
   â”‚   â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚     â”‚     â”‚  â”‚ S â”‚ â”‚ S â”‚ â”‚ S â”‚      â”‚
   â”‚   â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚     â”‚     â”‚  â”‚ 4 â”‚ â”‚ 5 â”‚ â”‚ 6 â”‚      â”‚
   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚     â”‚  â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜      â”‚
   â”‚                      â”‚     â”‚                          â”‚
   â”‚  â€¢ More CPU cores    â”‚     â”‚  â€¢ More machines         â”‚
   â”‚  â€¢ More RAM          â”‚     â”‚  â€¢ Load distributed      â”‚
   â”‚  â€¢ Faster disks      â”‚     â”‚  â€¢ Redundancy            â”‚
   â”‚                      â”‚     â”‚                          â”‚
   â”‚  âš ï¸ Has LIMITS       â”‚     â”‚  âš ï¸ Needs COORDINATION   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Scalability Spectrum

| Factor | Vertical Scaling | Horizontal Scaling |
|--------|------------------|-------------------|
| **Cost curve** | Exponential | Linear |
| **Ceiling** | Hardware limits | Nearly infinite |
| **Complexity** | Low | High |
| **Failure mode** | Single point of failure | Partial degradation |
| **When to use** | Early stage, simple apps | At scale, distributed |

### Real-World Example: Database Scaling

```
                    Database Growth Journey
                    
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Stage 1   â”‚     â”‚   Stage 2   â”‚     â”‚      Stage 3        â”‚
â”‚ Single Node â”‚ â†’   â”‚ Bigger Node â”‚ â†’   â”‚   Sharded Cluster   â”‚
â”‚  (1 CPU)    â”‚     â”‚  (32 CPUs)  â”‚     â”‚   (100s of nodes)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                   â”‚                       â”‚
   10 req/s            1K req/s              1M+ req/s
      â”‚                   â”‚                       â”‚
   $10/mo              $1000/mo                $50K/mo
                                            (but 50x scale)
```

### The Scalability Equation

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                  â”‚
                    â”‚   Capacity = f(Resources, N)     â”‚
                    â”‚                                  â”‚
                    â”‚   Where:                         â”‚
                    â”‚   â€¢ If linear: C = k Ã— N         â”‚
                    â”‚   â€¢ If sublinear: C = k Ã— log(N) â”‚
                    â”‚   â€¢ If superlinear: C = k Ã— NÂ²   â”‚
                    â”‚     (coordination overhead)      â”‚
                    â”‚                                  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> [!IMPORTANT]
> **Amdahl's Law**: The theoretical speedup is limited by the sequential portion of the program.
> If 5% of your code is sequential, you can never achieve more than 20x speedup, no matter how many servers you add.

---

## 2.1.3 Performance

### Definition

> **Performance** is how fast a single unit of work is completed.

### Key Performance Metrics

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       PERFORMANCE METRICS          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                                                          â”‚
   â”‚  REQUEST                                                 â”‚
   â”‚     â”‚                                                    â”‚
   â”‚     â–¼                                                    â”‚
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”  â”‚
   â”‚  â”‚ Net  â”‚ â†’ â”‚   Queuing    â”‚ â†’ â”‚ Process  â”‚ â†’ â”‚ Net  â”‚  â”‚
   â”‚  â”‚ In   â”‚   â”‚   (Waiting)  â”‚   â”‚ (Work)   â”‚   â”‚ Out  â”‚  â”‚
   â”‚  â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜  â”‚
   â”‚     â†‘              â†‘               â†‘            â†‘       â”‚
   â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
   â”‚                          â”‚                               â”‚
   â”‚              RESPONSE TIME (Latency)                     â”‚
   â”‚                                                          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   PROCESSING TIME: Time spent doing actual work
   WAITING TIME:    Time spent in queues
   RESPONSE TIME:   Total time from request to response
   
   Response Time = Processing Time + Waiting Time + Network Time
```

### Performance Percentiles

> [!TIP]
> **Never use averages for performance!** They hide the outliers that affect real users.

```
                    Response Time Distribution
                    
   Frequency
      â”‚
   â–ˆâ–ˆâ–ˆâ”‚
   â–ˆâ–ˆâ–ˆâ”‚ â–ˆâ–ˆ
   â–ˆâ–ˆâ–ˆâ”‚ â–ˆâ–ˆâ–ˆâ–ˆ
   â–ˆâ–ˆâ–ˆâ”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
   â–ˆâ–ˆâ–ˆâ”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
   â–ˆâ–ˆâ–ˆâ”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
   â–ˆâ–ˆâ–ˆâ”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
   â–ˆâ–ˆâ–ˆâ”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–’â–’â–’
   â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
      0ms   50ms  100ms  200ms  500ms  2s
                    â†‘     â†‘           â†‘
                   p50   p99         p99.9
                    
   â€¢ p50 = 50ms  (Median user experience)
   â€¢ p99 = 200ms (1 in 100 users sees this)
   â€¢ p99.9 = 2s  (1 in 1000 users is frustrated)
```

### Why p99 Matters

If your service has 1M requests/day:
- **p99 = 200ms**: 10,000 users/day wait 200ms+
- **p99.9 = 2s**: 1,000 users/day wait 2+ seconds

For e-commerce, each 100ms of latency costs ~1% of sales!

---

## 2.1.4 Scalability vs Performance

### The Critical Distinction

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                             â”‚
                    â”‚   PERFORMANCE:  How fast is ONE request?    â”‚
                    â”‚                                             â”‚
                    â”‚   SCALABILITY:  How many can we handle      â”‚
                    â”‚                 while maintaining speed?    â”‚
                    â”‚                                             â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Relationship Matrix

|  | High Performance | Low Performance |
|--|------------------|-----------------|
| **High Scalability** | âœ… The goal | âš ï¸ Scales but slow |
| **Low Scalability** | âš ï¸ Fast but breaks | âŒ Worst case |

### Real-World Example: The Ferrari vs The Bus

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   ğŸï¸ FERRARI (High Performance)  â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚   â€¢ 0-60 in 3 seconds            â”‚
                    â”‚   â€¢ Top speed: 200 mph           â”‚
                    â”‚   â€¢ Capacity: 2 people           â”‚
                    â”‚                                  â”‚
                    â”‚   â†’ HIGH PERFORMANCE             â”‚
                    â”‚   â†’ LOW SCALABILITY              â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   ğŸšŒ BUS (High Scalability)      â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚   â€¢ 0-60 in... eventually        â”‚
                    â”‚   â€¢ Top speed: 60 mph            â”‚
                    â”‚   â€¢ Capacity: 50+ people         â”‚
                    â”‚                                  â”‚
                    â”‚   â†’ LOWER PERFORMANCE            â”‚
                    â”‚   â†’ HIGH SCALABILITY             â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        Want to move 1 person fast? â†’ Ferrari
        Want to move 1000 people?   â†’ Bus fleet (horizontal scaling)
```

### The Scalability-Performance Trade-off in Distributed Systems

```
                          Response Time vs Load
   
   Latency
   (ms)                                           
      â”‚                                    â•­â”€â”€â”€ System breaks
   500â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®     â•±     (overload)
      â”‚                              â•²   â•±
   400â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
      â”‚                             â•±
   300â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
      â”‚                           â•±
   200â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•±
      â”‚   Stable latency      â•±
   100â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
      â”‚  â•±
    50â”œâ”€â•¯
      â”‚
    â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
      0    100    500   1000   2000   3000
                    
              Requests per second (Load)
              
   KEY INSIGHT: The "knee" of the curve is where scalability matters.
   A system with better scalability pushes the knee further right.
```

### ğŸ–¥ï¸ Live Demo: Seeing the Trade-off

**Step 1: Test Performance (single request)**

```bash
# Single request - fast!
time curl http://localhost:5001/data/test
# Response: ~10ms
```

**Step 2: Test Scalability (concurrent requests)**

```bash
# 50 concurrent requests - what happens to that 10ms?
python labs/scalability/client.py --target http://localhost:5001 \
    --concurrent 50 --requests 100 --verbose
```

**Observe**: Response time increases as load increases. The **knee of the curve** is where performance degrades.

---

## 2.1.5 Latency vs Throughput

### Definitions

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                             â”‚
                    â”‚   LATENCY:     Time for ONE request         â”‚
                    â”‚                (measured in ms)             â”‚
                    â”‚                                             â”‚
                    â”‚   THROUGHPUT:  Requests completed per       â”‚
                    â”‚                unit of time (req/s, QPS)    â”‚
                    â”‚                                             â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Inverse Relationship

> [!NOTE]
> Latency and throughput are **inversely related** under load.
> As you push more requests (throughput), latency increases.

```
                    The Latency-Throughput Trade-off
                    
   Latency                                      Throughput
   (ms)                                         (req/s)
      â”‚                                            â”‚
   500â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®                     2000â”œ
      â”‚                  â•²                         â”‚
   400â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²                   1500â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      â”‚                    â•²                       â”‚                     â•²
   300â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²                 1000â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²
      â”‚                      â•²                     â”‚                       â•²
   200â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²                500â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²
      â”‚                        â•²                   â”‚                         â•²
   100â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²                 â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
      â”‚                          â•²                  0      1      2      3
      â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º                         Load Factor
        0      1      2      3
                Load Factor           When load increases:
                                      â€¢ Latency goes UP â†‘
   As resources fill up, requests    â€¢ Throughput eventually DROPS â†“
   wait longer in queues.              (system can't keep up)
```

### The Pipeline Analogy

```
                    Water Pipeline Analogy
                    
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  LATENCY = How fast water moves through the pipe        â”‚
   â”‚  THROUGHPUT = How much water flows per second           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
   Scenario 1: Low Load
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â–º
   Water flows fast (low latency), not much volume (low throughput)
   
   Scenario 2: High Load
   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–º
   Pipe is full (high throughput), but PRESSURE builds
   Each drop takes longer (high latency)
   
   Scenario 3: Overload
   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆBLOCKEDâ–ˆ
   Pipe BURSTS! Neither latency nor throughput works.
```

### Little's Law

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                        â”‚
                    â”‚         L = Î» Ã— W                      â”‚
                    â”‚                                        â”‚
                    â”‚   L = Average items in system          â”‚
                    â”‚   Î» = Arrival rate (throughput)        â”‚
                    â”‚   W = Average wait time (latency)      â”‚
                    â”‚                                        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Example:**
- If requests arrive at **100 req/s** (Î»)
- And each takes **200ms** to complete (W = 0.2s)
- Then at any moment: **L = 100 Ã— 0.2 = 20 requests** are in the system

> [!TIP]
> Use Little's Law to size your server pools!
> If you need 500 req/s throughput with 100ms latency, you need 50 concurrent workers.

### When to Optimize for Each

| Optimize for **Latency** | Optimize for **Throughput** |
|--------------------------|----------------------------|
| Real-time gaming | Batch processing |
| Trading systems | Data pipelines |
| Video calls | Log aggregation |
| API gateways | ML training |

### The Latency-Throughput Spectrum

```
                    System Design Trade-offs
                    
   LOW LATENCY â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º HIGH THROUGHPUT
        â”‚                    â”‚                         â”‚
        â–¼                    â–¼                         â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Trading â”‚         â”‚   Web   â”‚              â”‚  Batch  â”‚
   â”‚ Systems â”‚         â”‚  APIs   â”‚              â”‚  Jobs   â”‚
   â”‚         â”‚         â”‚         â”‚              â”‚         â”‚
   â”‚ <1ms    â”‚         â”‚ <100ms  â”‚              â”‚ Minutes â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
   Design                    Design                   Design
   Choices:                  Choices:                 Choices:
   â€¢ In-memory only          â€¢ Caching                â€¢ Queue-based
   â€¢ Co-located servers      â€¢ Connection pools       â€¢ Parallel workers
   â€¢ UDP over TCP            â€¢ Async I/O              â€¢ Batch processing
   â€¢ Dedicated hardware      â€¢ CDN                    â€¢ Cheap compute
```

---

## ğŸ“Š Summary: The Four Concepts

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                 THE RELATIONSHIP                    â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚                                                     â”‚
                    â”‚      PERFORMANCE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â–º LATENCY       â”‚
                    â”‚         (Speed)            â”‚         (Time per      â”‚
                    â”‚                            â”‚          request)      â”‚
                    â”‚                            â”‚                        â”‚
                    â”‚                           \â”‚/                       â”‚
                    â”‚                            â–¼                        â”‚
                    â”‚                                                     â”‚
                    â”‚      SCALABILITY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â–º THROUGHPUT    â”‚
                    â”‚       (Capacity)                     (Requests      â”‚
                    â”‚                                       per second)   â”‚
                    â”‚                                                     â”‚
                    â”‚                                                     â”‚
                    â”‚   â€¢ Performance: How fast is ONE thing?             â”‚
                    â”‚   â€¢ Scalability: Can we do MANY things at speed?    â”‚
                    â”‚   â€¢ Latency: Time for one request                   â”‚
                    â”‚   â€¢ Throughput: Requests per second                 â”‚
                    â”‚                                                     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Key Takeaways

1. **Scalability â‰  Performance**
   - A Ferrari is fast (performance) but can't scale (2 seats)
   - A bus fleet is scalable but each bus is slower

2. **The Thundering Herd is a Scalability Problem**
   - Systems must handle not just steady load, but **recovery surges**
   - Always add **jitter** to backoff algorithms

3. **Little's Law Connects Them**
   - L = Î» Ã— W (Items = Throughput Ã— Latency)
   - Use this to size your systems

4. **Measure Percentiles, Not Averages**
   - p99 latency affects 1% of users
   - At scale, 1% = thousands of frustrated users

---

## ğŸ” Looking Ahead

This module sets the foundation for understanding **why** we need:
- **Load Balancing** (Module 2.2): Distribute work to scale horizontally
- **Rate Limiting** (Module 2.3): Protect against overload
- **Horizontal Scaling Demo** (Lab): See these concepts in action

---

## ğŸ“š Further Reading

- [Understanding the AWS October 2025 Outage](https://www.forbes.com/sites/kateoflahertyuk/2025/10/23/aws-outage-new-analysis-explains-what-went-wrong-and-why/)
- [Little's Law in Practice](https://en.wikipedia.org/wiki/Little%27s_law)
- [Amdahl's Law and Scalability](https://en.wikipedia.org/wiki/Amdahl%27s_law)
- [Tail Latencies and Why They Matter](https://cacm.acm.org/magazines/2013/2/160173-the-tail-at-scale/fulltext)
